{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goose3 import Goose\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from twisted.internet import reactor\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import tldextract\n",
    "import sys \n",
    "sys.path.append('../../scraper/Sitemap')\n",
    "import poli_sitemap_spider as poli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.lpbergeijk.nl\n",
      "http://www.lpbergeijk.nl\n"
     ]
    }
   ],
   "source": [
    "start_url = \"https://heerenveen.christenunie.nl\"\n",
    "extracted_domain = tldextract.extract(start_url)\n",
    "domain = extracted_domain[0]+'.'+extracted_domain[1]+'.'+extracted_domain[2]\n",
    "print(domain)\n",
    "print(start_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:41:10 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: scrapybot)\n",
      "2019-02-22 09:41:10 [scrapy.utils.log] INFO: Versions: lxml 4.3.1.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.6.7 (default, Oct 22 2018, 11:32:17) - [GCC 8.2.0], pyOpenSSL 19.0.0 (OpenSSL 1.1.1a  20 Nov 2018), cryptography 2.5, Platform Linux-4.20.0-042000-generic-x86_64-with-Ubuntu-18.04-bionic\n",
      "2019-02-22 09:41:10 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'csv', 'FEED_URI': 'links.csv'}\n",
      "2019-02-22 09:41:10 [scrapy.extensions.telnet] INFO: Telnet Password: 616ef8a596697886\n",
      "2019-02-22 09:41:10 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-02-22 09:41:10 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-02-22 09:41:10 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-02-22 09:41:10 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-02-22 09:41:10 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-02-22 09:41:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-02-22 09:41:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-02-22 09:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lpbergeijk.nl> (referer: None)\n",
      "2019-02-22 09:41:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lpbergeijk.nl/nieuws/> (referer: http://www.lpbergeijk.nl)\n",
      "2019-02-22 09:41:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.lpbergeijk.nl/nieuws/>\n",
      "{'url': 'http://www.lpbergeijk.nl/nieuws/'}\n",
      "2019-02-22 09:41:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.lpbergeijk.nl/nieuws/>\n",
      "{'url': 'http://www.lpbergeijk.nl/nieuws/page/2/'}\n",
      "2019-02-22 09:41:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.lpbergeijk.nl/nieuws/>\n",
      "{'url': 'http://www.lpbergeijk.nl/nieuws/page/3/'}\n",
      "2019-02-22 09:41:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.lpbergeijk.nl/nieuws/>\n",
      "{'url': 'http://www.lpbergeijk.nl/nieuws/page/4/'}\n",
      "2019-02-22 09:41:13 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.lpbergeijk.nl/nieuws/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)\n",
      "2019-02-22 09:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lpbergeijk.nl/nieuws/page/4/> (referer: http://www.lpbergeijk.nl/nieuws/)\n",
      "2019-02-22 09:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lpbergeijk.nl/nieuws/page/3/> (referer: http://www.lpbergeijk.nl/nieuws/)\n",
      "2019-02-22 09:41:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.lpbergeijk.nl/nieuws/page/2/> (referer: http://www.lpbergeijk.nl/nieuws/)\n",
      "2019-02-22 09:41:13 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-02-22 09:41:13 [scrapy.extensions.feedexport] INFO: Stored csv feed (4 items) in: links.csv\n",
      "2019-02-22 09:41:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 1293,\n",
      " 'downloader/request_count': 5,\n",
      " 'downloader/request_method_count/GET': 5,\n",
      " 'downloader/response_bytes': 271755,\n",
      " 'downloader/response_count': 5,\n",
      " 'downloader/response_status_count/200': 5,\n",
      " 'dupefilter/filtered': 13,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 2, 22, 8, 41, 13, 974036),\n",
      " 'item_scraped_count': 4,\n",
      " 'log_count/DEBUG': 10,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 122798080,\n",
      " 'memusage/startup': 122798080,\n",
      " 'request_depth_max': 3,\n",
      " 'response_received_count': 5,\n",
      " 'scheduler/dequeued': 5,\n",
      " 'scheduler/dequeued/memory': 5,\n",
      " 'scheduler/enqueued': 5,\n",
      " 'scheduler/enqueued/memory': 5,\n",
      " 'start_time': datetime.datetime(2019, 2, 22, 8, 41, 10, 865347)}\n",
      "2019-02-22 09:41:13 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process = CrawlerProcess({\n",
    "    'FEED_URI': 'links.csv',\n",
    "    'FEED_FORMAT': 'csv'\n",
    "})\n",
    "\n",
    "d = process.crawl(poli.PoliSitemapSpider, start_urls=[start_url], allowed_domains=[domain])\n",
    "d.addBoth(lambda _: reactor.stop())\n",
    "reactor.run() # the script will block here until the crawling is finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Goose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = pd.read_csv('./links.csv')\n",
    "urls = url_list['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:41:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): www.lpbergeijk.nl:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start scraping: http://www.lpbergeijk.nl/nieuws/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:41:19 [urllib3.connectionpool] DEBUG: http://www.lpbergeijk.nl:80 \"GET /nieuws/ HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done scraping: http://www.lpbergeijk.nl/nieuws/\n",
      "start scraping: http://www.lpbergeijk.nl/nieuws/page/2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:41:19 [urllib3.connectionpool] DEBUG: http://www.lpbergeijk.nl:80 \"GET /nieuws/page/2/ HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done scraping: http://www.lpbergeijk.nl/nieuws/page/2/\n",
      "start scraping: http://www.lpbergeijk.nl/nieuws/page/3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:41:20 [urllib3.connectionpool] DEBUG: http://www.lpbergeijk.nl:80 \"GET /nieuws/page/3/ HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done scraping: http://www.lpbergeijk.nl/nieuws/page/3/\n",
      "start scraping: http://www.lpbergeijk.nl/nieuws/page/4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:41:21 [urllib3.connectionpool] DEBUG: http://www.lpbergeijk.nl:80 \"GET /nieuws/page/4/ HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done scraping: http://www.lpbergeijk.nl/nieuws/page/4/\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "titles = []\n",
    "dates =[]\n",
    "for url in urls:\n",
    "    print(\"start scraping:\", url)\n",
    "    try: \n",
    "        \n",
    "        article = g.extract(url=url)\n",
    "        texts.append(article.cleaned_text)\n",
    "        titles.append(article.title)\n",
    "        dates.append(article.publish_date)\n",
    "        print(\"done scraping:\", url)\n",
    "    except MissingSchema: \n",
    "        print('Error scraping')\n",
    "g.close()\n",
    "\n",
    "url_list['body'] = texts\n",
    "url_list['title'] = titles\n",
    "url_list['publish_dates'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.lpbergeijk.nl/nieuws/</td>\n",
       "      <td>Opiniestuk in ED. (door Bart Verhagen) In de c...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.lpbergeijk.nl/nieuws/page/2/</td>\n",
       "      <td>In de raadsvergadering van donderdag 26 april ...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.lpbergeijk.nl/nieuws/page/3/</td>\n",
       "      <td>De titel van dit artikel verwijst naar de vers...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.lpbergeijk.nl/nieuws/page/4/</td>\n",
       "      <td>Het is al weer ruim 20 jaar geleden dat de gem...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   html                                      url  \\\n",
       "0   NaN         http://www.lpbergeijk.nl/nieuws/   \n",
       "1   NaN  http://www.lpbergeijk.nl/nieuws/page/2/   \n",
       "2   NaN  http://www.lpbergeijk.nl/nieuws/page/3/   \n",
       "3   NaN  http://www.lpbergeijk.nl/nieuws/page/4/   \n",
       "\n",
       "                                                body title publish_dates  \n",
       "0  Opiniestuk in ED. (door Bart Verhagen) In de c...                None  \n",
       "1  In de raadsvergadering van donderdag 26 april ...                None  \n",
       "2  De titel van dit artikel verwijst naar de vers...                None  \n",
       "3  Het is al weer ruim 20 jaar geleden dat de gem...                None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
